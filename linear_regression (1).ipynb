{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cbce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake = pd.read_csv('Fake.csv')\n",
    "data_true = pd.read_csv('True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8225860",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake[\"class\"] = 0\n",
    "data_true[\"class\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake.shape, data_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d9f886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cd8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the last 10 rows of data_fake\n",
    "data_fake_manual_testing = data_fake.tail(10)\n",
    "\n",
    "# Remove rows from 23480 to 23471 in data_fake\n",
    "for i in range(23480, 23470, -1):\n",
    "    if i in data_fake.index:  # Ensure the index exists before dropping\n",
    "        data_fake.drop([i], axis=0, inplace=True)\n",
    "\n",
    "# Select the last 10 rows of data_fake again (optional)\n",
    "data_true_manual_testing = data_fake.tail(10)\n",
    "\n",
    "# Remove rows from 21416 to 21407 in data_true\n",
    "for i in range(21416, 21406, -1):\n",
    "    if i in data_true.index:  # Ensure the index exists before dropping\n",
    "        data_true.drop([i], axis=0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5a580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake_manual_testing['class'] = 0\n",
    "data_true_manual_testing['class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake_manual_testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf3720",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true_manual_testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge = pd.concat([data_fake, data_true] , axis = 0)\n",
    "data_merge.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_merge.drop(['title', 'subject', 'date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b63dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace = True)\n",
    "data.drop(['index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb52f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8856f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce713bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordopt(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]','', text)\n",
    "    text = re.sub(\"\\\\W\", \" \", text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+','',text)\n",
    "    text = re.sub('<.*?>+','',text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation),'',text)\n",
    "    text = re.sub('\\n','', text)\n",
    "    text = re.sub('\\w*\\d\\w*','',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06262d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(wordopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ce4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['text']\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a466002",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train, y_test = train_test_split(x,y,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b21f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "vectorization = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform training data\n",
    "xv_train = vectorization.fit_transform(x_train)\n",
    "\n",
    "# Transform test data\n",
    "xv_test = vectorization.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186843ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(xv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f71723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = LR.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b0ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.score(xv_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c43b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a78729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained Logistic Regression model\n",
    "joblib.dump(LR, 'news_model.pkl')\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "joblib.dump(vectorization, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "print(\"Model and vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a88c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and vectorizer\n",
    "model = joblib.load('news_model.pkl')\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Example usage\n",
    "user_input = input(\"Enter a news article: \")\n",
    "vectorized_input = vectorizer.transform([user_input])  # Transform user input\n",
    "prediction = model.predict(vectorized_input)\n",
    "result = \"True News\" if prediction[0] == 1 else \"Fake News\"\n",
    "print(f\"The article is classified as: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7338be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Function to classify user input\n",
    "def classify_news(user_text, LR, vectorization):\n",
    "    \"\"\"\n",
    "    Classifies the input news article as 'True News' or 'Fake News' using a pre-trained model and TF-IDF vectorizer.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_text (str): The input news article to classify.\n",
    "    - LR: The trained Logistic Regression model.\n",
    "    - vectorization: The TF-IDF vectorizer used to transform text.\n",
    "    \n",
    "    Returns:\n",
    "    - str: \"True News\" or \"Fake News\" based on the classification result.\n",
    "    \"\"\"\n",
    "    # Clean the input text (assuming you have a wordopt function for cleaning)\n",
    "    cleaned_text = wordopt(user_text)\n",
    "\n",
    "    # Transform the text to TF-IDF vector\n",
    "    vectorized_text = vectorization.transform([cleaned_text]).toarray()\n",
    "\n",
    "    # Predict using the trained Logistic Regression model (LR)\n",
    "    prediction = LR.predict(vectorized_text)\n",
    "\n",
    "    # Return the result\n",
    "    return \"True News\" if prediction[0] == 1 else \"Fake News\"\n",
    "\n",
    "# Function to load the model and vectorizer\n",
    "def load_model_and_vectorizer(model_path='news_model.pkl', vectorizer_path='tfidf_vectorizer.pkl'):\n",
    "    \"\"\"\n",
    "    Loads the trained Logistic Regression model and TF-IDF vectorizer from the provided file paths.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_path (str): Path to the saved Logistic Regression model.\n",
    "    - vectorizer_path (str): Path to the saved TF-IDF vectorizer.\n",
    "    \n",
    "    Returns:\n",
    "    - LR: The loaded Logistic Regression model.\n",
    "    - vectorization: The loaded TF-IDF vectorizer.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        LR = joblib.load(model_path)           # Load the trained Logistic Regression model\n",
    "        vectorization = joblib.load(vectorizer_path)      # Load the trained TF-IDF vectorizer\n",
    "        print(\"Model and vectorizer loaded successfully!\")\n",
    "        return LR, vectorization\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model or vectorizer file not found. Please check the paths.\")\n",
    "        return None, None\n",
    "\n",
    "# Load the model and vectorizer\n",
    "LR, vectorization = load_model_and_vectorizer()\n",
    "\n",
    "# If model and vectorizer are loaded successfully, classify the user input\n",
    "if LR is not None and vectorization is not None:\n",
    "    user_input = input(\"Enter a news article: \")\n",
    "    result = classify_news(user_input, LR, vectorization)\n",
    "    print(f\"The article is classified as: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7e2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
